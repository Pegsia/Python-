{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习算法（二）: 朴素贝叶斯(Naive Bayes)\r\n",
    "\r\n",
    "## 1. 实验室介绍\r\n",
    "\r\n",
    "### 1.1 实验环境\r\n",
    "\r\n",
    "```\r\n",
    "1. python3.7\r\n",
    "2. numpy >= '1.16.4'\r\n",
    "3. sklearn >= '0.23.1'\r\n",
    "```\r\n",
    "\r\n",
    "### 1.2 朴素贝叶斯的介绍\r\n",
    "\r\n",
    "朴素贝叶斯算法（Naive Bayes, NB) 是应用最为广泛的分类算法之一。它是基于贝叶斯定义和特征条件独立假设的分类器方法。由于朴素贝叶斯法基于贝叶斯公式计算得到，有着坚实的数学基础，以及稳定的分类效率。NB模型所需估计的参数很少，对缺失数据不太敏感，算法也比较简单。当年的垃圾邮件分类都是基于朴素贝叶斯分类器识别的。\r\n",
    "\r\n",
    "什么是条件概率，我们从一个摸球的例子来理解。我们有两个桶：灰色桶和绿色桶，一共有7个小球，4个蓝色3个紫色，分布如下图：\r\n",
    "\r\n",
    "<img src=\"http://tianchi-media.oss-cn-beijing.aliyuncs.com/DSW/2NaiveBayes/ball_ab.png\" />\r\n",
    "\r\n",
    "从这7个球中，随机选择1个球是紫色的概率p是多少？选择过程如下：\r\n",
    "\r\n",
    "1. 先选择桶\r\n",
    "2. 再从选择的桶中选择一个球\r\n",
    "\r\n",
    "$$\r\n",
    "p(球=紫色) \\\\\r\n",
    "=p(选择灰桶) \\cdot p(从灰桶中选择紫色) + p(选择绿桶) \\cdot p(从绿桶中选择紫色) \\\\\r\n",
    "=\\frac{1}{2} \\cdot \\frac{2}{4} + \\frac{1}{2} \\cdot \\frac{1}{3}\r\n",
    "$$\r\n",
    "\r\n",
    "上述我们选择小球的过程就是条件概率的过程，在选择桶的颜色的情况下是紫色的概率，另一种计算条件概率的方法是贝叶斯准则。\r\n",
    "\r\n",
    "贝叶斯公式是英国数学家提出的一个数据公式:\r\n",
    "\r\n",
    "$$\r\n",
    "p(A|B)=\\frac{p(A,B)}{p(B)}=\\frac{p(B|A) \\cdot p(A)}{\\sum_{a \\in ℱ_A}p(B|a) \\cdot p(a)}\r\n",
    "$$\r\n",
    "\r\n",
    "p(A,B)：表示事件A和事件B同时发生的概率。\r\n",
    "\r\n",
    "p(B)：表示事件B发生的概率，叫做先验概率；p(A)：表示事件A发生的概率。\r\n",
    "\r\n",
    "p(A|B)：表示当事件B发生的条件下，事件A发生的概率叫做后验概率。\r\n",
    "\r\n",
    "p(B|A)：表示当事件A发生的条件下，事件B发生的概率。\r\n",
    "\r\n",
    "我们用一句话理解贝叶斯：世间很多事都存在某种联系，假设事件A和事件B。人们常常使用已经发生的某个事件去推断我们想要知道的之间的概率。\r\n",
    "例如，医生在确诊的时候，会根据病人的舌苔、心跳等来判断病人得了什么病。对病人来说，只会关注得了什么病，医生会通道已经发生的事件来\r\n",
    "确诊具体的情况。这里就用到了贝叶斯思想，A是已经发生的病人症状，在A发生的条件下是B_i的概率。\r\n",
    "\r\n",
    "\r\n",
    "### 1.3 朴素贝叶斯的应用\r\n",
    "\r\n",
    "朴素贝叶斯算法<font color = #32cd99f>假设所有特征的出现相互独立互不影响，每一特征同等重要</font>，又因为其简单，而且具有很好的可解释性一般。相对于其他精心设计的更复杂的分类算法，朴素贝叶斯分类算法是学习效率和分类效果较好的分类器之一。朴素贝叶斯算法一般应用在文本分类，垃圾邮件的分类，信用评估，钓鱼网站检测等。\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯算法\r\n",
    "\r\n",
    "朴素贝叶斯法 = 贝叶斯定理 + 特征条件独立。\r\n",
    "\r\n",
    "> 输入$X \\in R^n$空间是n维向量集合，输出空间$y=\\{c_1,c_2,...,c_K\\}$. 所有的X和y都是对应空间上的随机变量. $P(X,Y)$是X和Y的联合概率分布. 训练数据集(由$P(X,Y)$独立同分布产生):\r\n",
    "> $$T=\\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\\}$$ \r\n",
    "\r\n",
    "计算测试数据x的列表，我们需要依次计算$P(Y=c_k|X=x)$，取概率最大的值，就是x对应的分类。\r\n",
    "\r\n",
    "$P(Y=c_k|X=x)$我们一般这样解释，当给定$(X=x)$的条件下，$Y=c_k$的概率，这就是条件概率. 这就简单了，我们只需要每个的x，计算其对应的$c_k,k \\in [1,2,...,K]$的概率，选择最大的概率作为这个x的类别进行了. \r\n",
    "\r\n",
    "通过贝叶斯公式进行变形，得到预测的概率计算公式：\r\n",
    "\r\n",
    "$$P(Y=c_k|X=x)=\\frac{P(X=x|Y=c_k)P(Y=c_k)}{\\sum_{k}P(X=x|Y=c_k)P(Y=c_k)}$$\r\n",
    "\r\n",
    "我们只需要计算以下两个概率即可，又由于朴素贝叶斯假设条件独立，我们可以单独计算每个特征的条件概率：$P(X^{(i)}=x^{(i)}|Y=c_k)$和类目$c_k$的先验概率：$P(Y=c_k)$。为了更好的理解这个公式，看下图解释：\r\n",
    "\r\n",
    "其中：\r\n",
    "$$\r\n",
    "P(Y=c_k)=\\frac{\\sum_{i=1}^{N}I(y_i=c_k)}{N}, k=1,2,...,K\r\n",
    "$$\r\n",
    "\r\n",
    "当涉及到多个条件时，朴素贝叶斯有一个提前的假设，我们称之为 条件独立性假设（或者 简单假设：Naive）：公式如下\r\n",
    "$$\r\n",
    "P(A,B|Y) = P(A|Y) \\cdot P(B|Y)\r\n",
    "$$\r\n",
    "这个公式是朴素贝叶斯的基础假设，即各个条件概率是相互独立的，A不影响B，B不影响A。\r\n",
    "而对这里来说，假设$X = [x_1,x_2,...,x_n]$\r\n",
    "\r\n",
    "$$\r\n",
    "P(X=x|Y=c_k) \\\\\r\n",
    "=P(X^{(1)}=x^{(1)},X^{(2)}=x^{(2)},...,X^{(n)}=x^{(n)}|Y=c_k) \\\\\r\n",
    "=\\prod_{i=1}^{n} P(x_i | y)\r\n",
    "$$\r\n",
    "\r\n",
    "由此原式可以等价为：\r\n",
    "\r\n",
    "$$P(Y=c_k|X=x)=\\frac{\\prod_{i=1}^{n} P(x_i | Y=c_k)P(Y=c_k)}{\\sum_{k}\\prod_{i=1}^{n} P(x_i | Y=c_k)P(Y=c_k)}$$\r\n",
    "\r\n",
    "我们为了选择后验概率最大的结果，进行概率的比较，由于分母一致，这里直接去掉分母，得到最后的计算公式。\r\n",
    "\r\n",
    "$$\r\n",
    "y=arg max_{c_k}P(Y=c_k)\\prod_{j}P(X^{(j)}=x^{(j)}|Y=c_k)\r\n",
    "$$\r\n",
    "\r\n",
    "<img src=\"http://tianchi-media.oss-cn-beijing.aliyuncs.com/DSW/2NaiveBayes/bayes2.png\" />\r\n",
    "\r\n",
    "我们来看一个实例，更好的理解贝叶斯的计算过程，根据天气和是否是周末预测一个人是否会出门。\r\n",
    "\r\n",
    "|index|$X_1:$天气的好坏|$X_2:$是否周末|$Y:$是否出门|\r\n",
    "|:---:|:---:|:---:|:---:|\r\n",
    "|1|好|是|出门|\r\n",
    "|2|好|否|出门|\r\n",
    "|3|好|是|不出门|\r\n",
    "|4|好|否|出门|\r\n",
    "|5|不好|是|出门|\r\n",
    "|6|不好|否|不出门|\r\n",
    "\r\n",
    "根据上述数据，为了更好的理解计算过程，我们给出几个计算公式:\r\n",
    "\r\n",
    "\r\n",
    "a. 当出门的条件下，X_1是天气不好的概率:\r\n",
    "$$\r\n",
    "p(X_1=不好|Y=出门)\r\n",
    "=\\frac{p(X_1=不好,Y=出门)}{p(Y=出门)}=\\frac{1}{4}\r\n",
    "$$\r\n",
    "\r\n",
    "b. 出门的概率\r\n",
    "$$\r\n",
    "p(Y=出门)=\\frac{4}{6}\r\n",
    "$$\r\n",
    "\r\n",
    "c. X_1天气不好的概率、\r\n",
    "$$\r\n",
    "p(X_1=不好)=\\frac{2}{6}\r\n",
    "$$\r\n",
    "\r\n",
    "d. 在X_1天气不好的情况下，出门的概率:\r\n",
    "$$\r\n",
    "p(Y=出门|X_1=不好)=\\frac{p(X_1=不好|Y=出门) \\cdot p(Y=出门)}{p(X=不好)} \\\\\r\n",
    "=\\frac{\\frac{1}{4} \\cdot \\frac{4}{6}}{\\frac{2}{6}}=\\frac{1}{2}\r\n",
    "$$\r\n",
    "\r\n",
    "f. 在X_1天气不好的情况下，不出门的概率:\r\n",
    "$$\r\n",
    "p(Y=出门|X_1=不好)=1-p(Y=不出门|X_1=不好)=1-\\frac{1}{2}=\\frac{1}{2}\r\n",
    "$$\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 实验室手册\n",
    "\n",
    "### 2.1 学习目标\n",
    "\n",
    "1. 掌握贝叶斯公式\n",
    "2. 结合两个实例了解贝朴素叶斯的参数估计\n",
    "3. 掌握贝叶斯估计\n",
    "\n",
    "### 2.2 代码流程\n",
    "* Part 1. 莺尾花数据集--贝叶斯分类\n",
    "    + Step1: 库函数导入\n",
    "    + Step2: 数据导入&分析 \n",
    "    + Step3: 模型训练 \n",
    "    + Step4: 模型预测\n",
    "    + Step5: 原理简析\n",
    "     \n",
    "* Part 2. 模拟离散数据集--贝叶斯分类\n",
    "    + Step1: 库函数导入\n",
    "    + Step2: 数据导入&分析 \n",
    "    + Step3: 模型训练&可视化\n",
    "    + Step4: 原理简析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 算法实战"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 莺尾花数据集--贝叶斯分类\n",
    "\n",
    "**Step1: 库函数导入**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "import numpy as np\r\n",
    "# 加载鸢尾花数据集\r\n",
    "from sklearn import datasets\r\n",
    "# 导入高斯朴素贝叶斯分类器\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step2: 数据导入&分析**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_iris(return_X_y=True)\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们需要计算两个概率分别是：条件概率：$P(X^{(i)}=x^{(i)}|Y=c_k)$和类目$c_k$的先验概率：$P(Y=c_k)$。\n",
    "\n",
    "通过分析发现训练数据是数值类型的数据，这里假设每个特征服从高斯分布，因此我们选择高斯朴素贝叶斯来进行分类计算。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step3: 模型训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(var_smoothing=1e-08)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用高斯朴素贝叶斯进行计算\r\n",
    "clf = GaussianNB(var_smoothing = 1e-8)\r\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step4: 模型预测**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc:  0.967\n",
      "[2]\n",
      "预测的概率值: [[1.63542393e-232 2.18880483e-006 9.99997811e-001]]\n"
     ]
    }
   ],
   "source": [
    "# 评估\r\n",
    "y_pred = clf.predict(X_test)\r\n",
    "acc = np.sum(y_test == y_pred) / X_test.shape[0]\r\n",
    "print(\"Test Acc: % .3f\" % acc)\r\n",
    "\r\n",
    "# 预测\r\n",
    "y_proba = clf.predict_proba(X_test[:1])\r\n",
    "print(clf.predict(X_test[:1]))\r\n",
    "print(\"预测的概率值:\", y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step5: 原理简析**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "高斯朴素贝叶斯假设每个特征都服从高斯分布，我们把一个随机变量X服从数学期望为μ，方差为σ^2的数据分布称为高斯分布。对于每个特征我们一般使用平均值来估计μ和使用所有特征的方差估计σ^2。\n",
    "\n",
    "$$\n",
    "P(X^{(i)}=x^{(i)}|Y=c_k) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_y}} \\exp\\left(-\\frac{(x^{(i)} - \\mu_{c_k})^2}{2\\sigma^2_{c_k}}\\right)\n",
    "$$\n",
    "\n",
    "从上述例子中的预测结果中，我们可以看到类别2对应的后验概率值最大，所以我们认为类目2是最优的结果。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模拟离散数据集--贝叶斯分类\n",
    "**Step1: 库函数导入**\n",
    "    + Step2: 数据导入&分析 \n",
    "    + Step3: 模型训练&可视化\n",
    "    + Step4: 原理简析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\r\n",
    "# 使用基于类目特征的朴素贝叶斯\r\n",
    "from sklearn.naive_bayes import CategoricalNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step2: 数据导入&分析**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1)\r\n",
    "X = rng.randint(5, size = (600, 100))\r\n",
    "y = np.array([1, 2, 3, 4, 5, 6] * 100)\r\n",
    "data = np.c_[X, y]\r\n",
    "# X和y进行整体打散\r\n",
    "random.shuffle(data)\r\n",
    "X = data[:,:-1]\r\n",
    "y = data[:, -1]\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有的数据特征都是离散特征，我们引入基于离散特征的朴素贝叶斯分类器。\n",
    "\n",
    "**Step3: 模型训练&预测**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc :  0.667\n"
     ]
    }
   ],
   "source": [
    "clf = CategoricalNB(alpha = 1)\r\n",
    "clf.fit(X_train, y_train)\r\n",
    "acc = clf.score(X_test, y_test)\r\n",
    "print(\"Test Acc : % .3f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.60326578e-06 4.27679622e-03 6.49839783e-03 2.12088737e-06\n",
      "  9.19096325e-01 7.01207565e-02]]\n",
      "[5]\n"
     ]
    }
   ],
   "source": [
    "# 随机数据测试，分析预测结果，贝叶斯会选择概率最大的预测结果\r\n",
    "x = rng.randint(5, size = (1, 100))\r\n",
    "print(clf.predict_proba(x))\r\n",
    "print(clf.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 原理简析\n",
    "\n",
    "### 2.4.1 结果分析\n",
    "\n",
    "可以看到测试的数据的结果，贝叶斯会选择概率最大的预测结果，比如这里的预测结果是6，6对应的概率最大，由于我们是随机数据，读者运行的时候，可能会出现不一样的结果。\n",
    "\n",
    "这里的测试数据的准确率没有任何意义，因为数据是随机生成的，不一定具有贝叶斯先验性，这里只是作为一个列子引导大家如何使用。\n",
    "\n",
    "alpha=1这个参数表示什么？\n",
    "\n",
    "我们知道贝叶斯法一定要计算两个概率：条件概率：$P(X^{(i)}=x^{(i)}|Y=c_k)$和类目$c_k$的先验概率：$P(Y=c_k)$。\n",
    "\n",
    "对于离散特征：\n",
    "\n",
    "$$\n",
    "P(X^{(j)}=x^{(j)}|Y=c_k)=\\frac{\\sum_{i=1}^{N}I(x_i^j=a_{jl},y_i=c_k)+\\alpha}{\\sum_{i=1}^{N}I(y_i=c_k)+S_j\\alpha} \n",
    "$$\n",
    "\n",
    "我们可以看出就是对每一个变量的多加了一个频数alpha。当alphaλ=0时，就是极大似然估计。通常取值alpha=1，这就是拉普拉斯平滑(Laplace smoothing)，这有叫做贝叶斯估计，主要是因为如果使用极大似然估计，如果某个特征值在训练数据中没有出现，这时候会出现概率为0的情况，导致整个估计都为0，因为引入贝叶斯估计。\n",
    "\n",
    "其中：\n",
    "\n",
    "$S_j$：表示第j个特征的个数。\n",
    "\n",
    "$x_i^j$：表示第i个样本的第j维元素。\n",
    "\n",
    "$y_i$：第i个样本的label。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e5edc721c267c354f7c3a43761a84baa24063647031c2095a95e3fbc9f4e28d2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}